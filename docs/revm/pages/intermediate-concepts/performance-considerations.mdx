---
title: Performance Considerations
description: Detailed guide about performance considerations in REVM (Rust Ethereum Virtual Machine)
---

# Performance Considerations

This document explores performance optimization techniques for REVM, including identifying performance hotspots, caching strategies, memory usage patterns, benchmarking, and practical optimizations for different use cases.

## Understanding REVM Performance

REVM is designed to be a high-performance Ethereum Virtual Machine implementation, but performance can be further optimized for specific use cases. Before diving into optimization techniques, it's important to understand where performance bottlenecks typically occur.

### Common Performance Hotspots

In typical REVM usage, these areas often become performance bottlenecks:

1. **State Access**: Reading and writing account and storage state
2. **Bytecode Execution**: Interpreting and executing bytecode
3. **Gas Calculation**: Computing gas costs, especially for complex operations
4. **Memory Management**: Allocations and copies during execution
5. **Precompile Execution**: Some cryptographic precompiles are computationally intensive

### Performance Characteristics

REVM's performance characteristics vary by operation:

| Operation | Relative Cost | Common Bottlenecks |
|-----------|---------------|-------------------|
| Simple Transfers | Low | State access, signature verification |
| Contract Calls | Medium | State access, bytecode execution |
| Contract Creation | High | Bytecode execution, state writes |
| Precompile Calls | Variable | Cryptographic operations, input size |
| Storage-Heavy Operations | Very High | State access, trie operations |

## Caching Strategies

One of the most effective ways to improve REVM performance is through appropriate caching.

### State Caching

REVM provides the `CacheDB` wrapper to cache state access:

```rust
use revm::database::{CacheDB, EmptyDB};

// Create a cached database
let mut db = CacheDB::new(EmptyDB::default());

// State access is now cached
let account_info = db.basic(address)?;
// Second access will be from cache
let same_account_info = db.basic(address)?;
```

#### Cache Warming

For known access patterns, you can warm the cache in advance:

```rust
// Warm cache with frequently accessed accounts
let hot_accounts = [
    address!("0x1000000000000000000000000000000000000000"),
    address!("0x2000000000000000000000000000000000000000"),
    // ... other frequently accessed addresses
];

for account in hot_accounts {
    db.basic(account)?;
}
```

#### Cache Size Management

For long-running applications, you might need to manage cache size:

```rust
// Create a cache with capacity limits
struct BoundedCacheDB<DB> {
    inner: CacheDB<DB>,
    max_accounts: usize,
    max_storage_entries: usize,
}

impl<DB: Database> BoundedCacheDB<DB> {
    fn new(db: DB, max_accounts: usize, max_storage_entries: usize) -> Self {
        Self {
            inner: CacheDB::new(db),
            max_accounts,
            max_storage_entries,
        }
    }
    
    fn prune_if_needed(&mut self) {
        // Check account cache size
        if self.inner.accounts.len() > self.max_accounts {
            // Simple strategy: remove least recently used entries
            // In a real implementation, use a proper LRU algorithm
            self.inner.accounts.clear();
        }
        
        // Check storage cache size
        let storage_entries: usize = self.inner.accounts
            .values()
            .map(|acc| match acc {
                CacheAccount::Loaded { storage, .. } => storage.len(),
                _ => 0,
            })
            .sum();
            
        if storage_entries > self.max_storage_entries {
            // Clear all storage caches
            for account in self.inner.accounts.values_mut() {
                if let CacheAccount::Loaded { storage, .. } = account {
                    storage.clear();
                }
            }
        }
    }
}

// Implement Database trait for BoundedCacheDB
// ...
```

### Code Caching

REVM already caches contract code, but you can enhance this for specific patterns:

```rust
// Pre-load commonly executed contracts
let common_contracts = [
    (address!("0x1111111111111111111111111111111111111111"), bytecode1),
    (address!("0x2222222222222222222222222222222222222222"), bytecode2),
    // ... other common contracts
];

for (address, bytecode) in common_contracts {
    let account_info = AccountInfo {
        nonce: 0,
        balance: U256::ZERO,
        code_hash: keccak256(&bytecode),
        code: Some(Bytecode::new_raw(bytecode)),
    };
    db.insert_account_info(address, account_info);
}
```

### Bytecode Analysis Caching

REVM performs bytecode analysis for optimization. You can cache this analysis:

```rust
// Cache bytecode analysis results
let mut analysis_cache = HashMap::new();

// Before executing a contract
let code_hash = account_info.code_hash;
let bytecode = account_info.code.clone().unwrap_or_default();

// Check if analysis exists in cache
let analysis = if let Some(analysis) = analysis_cache.get(&code_hash) {
    analysis.clone()
} else {
    // Analyze bytecode
    let analysis = bytecode.clone().analyse();
    
    // Store in cache
    analysis_cache.insert(code_hash, analysis.clone());
    
    analysis
};

// Use the analyzed bytecode
let bytecode_with_analysis = bytecode.with_analysis(analysis);
```

## Memory Usage Optimization

Memory usage can significantly impact performance, especially in constrained environments.

### Minimizing Allocations

Reduce allocations in performance-critical paths:

```rust
// Avoid creating new vectors in hot paths
// Instead, reuse pre-allocated buffers

// Bad: Creates a new vector for each call
fn process_data_bad(data: &[u8]) -> Vec<u8> {
    let mut result = Vec::with_capacity(data.len());
    for byte in data {
        result.push(byte + 1);
    }
    result
}

// Better: Uses a pre-allocated buffer
struct DataProcessor {
    buffer: Vec<u8>,
}

impl DataProcessor {
    fn new() -> Self {
        Self {
            buffer: Vec::with_capacity(1024), // Pre-allocate
        }
    }
    
    fn process_data(&mut self, data: &[u8]) -> &[u8] {
        self.buffer.clear(); // Reuse the buffer
        self.buffer.reserve(data.len());
        
        for byte in data {
            self.buffer.push(byte + 1);
        }
        
        &self.buffer
    }
}
```

### Memory-Mapped Storage

For large-scale state, consider memory-mapped storage:

```rust
use memmap2::{MmapMut, MmapOptions};
use std::fs::{File, OpenOptions};
use std::path::Path;

struct MmapStorage {
    map: MmapMut,
    index: HashMap<(Address, U256), usize>, // Maps keys to offsets
}

impl MmapStorage {
    fn new(path: &Path, size: usize) -> std::io::Result<Self> {
        let file = OpenOptions::new()
            .read(true)
            .write(true)
            .create(true)
            .open(path)?;
            
        file.set_len(size as u64)?;
        
        let map = unsafe { MmapOptions::new().map_mut(&file)? };
        
        Ok(Self {
            map,
            index: HashMap::new(),
        })
    }
    
    fn get(&self, address: Address, key: U256) -> Option<U256> {
        self.index.get(&(address, key)).map(|&offset| {
            let mut bytes = [0u8; 32];
            bytes.copy_from_slice(&self.map[offset..offset + 32]);
            U256::from_be_bytes(bytes)
        })
    }
    
    fn set(&mut self, address: Address, key: U256, value: U256) {
        let offset = self.allocate_space();
        self.index.insert((address, key), offset);
        
        let bytes = value.to_be_bytes::<32>();
        self.map[offset..offset + 32].copy_from_slice(&bytes);
    }
    
    fn allocate_space(&mut self) -> usize {
        // Simple allocation strategy
        // In a real implementation, use a proper allocator
        let next_offset = self.index.values().max().unwrap_or(&0) + 32;
        assert!(next_offset + 32 <= self.map.len());
        next_offset
    }
}
```

### Bytecode Representation

REVM already optimizes bytecode representation, but for custom implementations:

```rust
// Specialized bytecode representation for contracts
// with many identical code segments
struct SharedBytecode {
    segments: HashMap<B256, Bytes>, // Unique segments
    sequence: Vec<B256>,           // Segment sequence
}

impl SharedBytecode {
    fn new(bytecode: &[u8]) -> Self {
        // Split bytecode into segments and deduplicate
        // ...
        
        Self {
            segments: HashMap::new(),
            sequence: Vec::new(),
        }
    }
    
    fn get_byte(&self, offset: usize) -> Option<u8> {
        // Find segment and offset within segment
        // ...
        
        None // Placeholder
    }
}
```

## Database Optimizations

The database implementation can significantly impact REVM performance.

### Efficient Database Implementation

```rust
use revm::database_interface::{Database, DatabaseRef, DBErrorMarker};
use revm::primitives::{Address, B256, U256};
use revm::state::AccountInfo;

// Performance-optimized database
struct OptimizedDB {
    // Use specialized data structures
    accounts: FnvHashMap<Address, AccountInfo>,
    storage: FnvHashMap<(Address, U256), U256>,
    code: FnvHashMap<B256, Bytecode>,
    blocks: FnvHashMap<u64, B256>,
    
    // Statistics for optimization
    access_counts: FnvHashMap<Address, usize>,
}

impl OptimizedDB {
    fn new() -> Self {
        Self {
            accounts: FnvHashMap::default(),
            storage: FnvHashMap::default(),
            code: FnvHashMap::default(),
            blocks: FnvHashMap::default(),
            access_counts: FnvHashMap::default(),
        }
    }
    
    fn update_stats(&mut self, address: Address) {
        *self.access_counts.entry(address).or_insert(0) += 1;
    }
    
    fn get_hot_accounts(&self, threshold: usize) -> Vec<Address> {
        self.access_counts
            .iter()
            .filter(|(_, &count)| count >= threshold)
            .map(|(&addr, _)| addr)
            .collect()
    }
}

impl Database for OptimizedDB {
    type Error = OptimizedDBError;
    
    fn basic(&mut self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        self.update_stats(address);
        Ok(self.accounts.get(&address).cloned())
    }
    
    // Implement other methods...
}
```

### Batched Database Operations

For operations involving multiple state changes:

```rust
// Batch database operations
struct BatchOperation {
    account_updates: Vec<(Address, Option<AccountInfo>)>,
    storage_updates: Vec<(Address, U256, U256)>,
}

impl BatchOperation {
    fn new() -> Self {
        Self {
            account_updates: Vec::new(),
            storage_updates: Vec::new(),
        }
    }
    
    fn update_account(&mut self, address: Address, info: Option<AccountInfo>) {
        self.account_updates.push((address, info));
    }
    
    fn update_storage(&mut self, address: Address, key: U256, value: U256) {
        self.storage_updates.push((address, key, value));
    }
}

// Apply batch to database
fn apply_batch(db: &mut impl Database, batch: BatchOperation) -> Result<(), Box<dyn Error>> {
    // Apply all updates in a single transaction
    // This depends on the specific database implementation
    
    for (address, info) in batch.account_updates {
        if let Some(info) = info {
            db.insert_account_info(address, info)?;
        } else {
            db.remove_account(address)?;
        }
    }
    
    for (address, key, value) in batch.storage_updates {
        db.insert_account_storage(address, key, value)?;
    }
    
    Ok(())
}
```

## Gas Optimization

Gas calculation can be a significant overhead in REVM execution.

### Specialized Gas Calculation

For known transaction patterns, you can optimize gas calculation:

```rust
// Fast path for simple transfers
fn calculate_transfer_gas(tx: &TxEnv) -> u64 {
    // Simple value transfer costs exactly 21,000 gas
    if let TxKind::Call(_) = tx.kind {
        if tx.data.is_empty() {
            return 21_000;
        }
    }
    
    // For other transactions, use standard calculation
    calculate_intrinsic_gas(tx)
}

// Use fast path when possible
let gas_used = if is_simple_transfer(tx) {
    calculate_transfer_gas(tx)
} else {
    calculate_intrinsic_gas(tx)
};
```

### Gas Cost Caching

For repeated operations, cache gas costs:

```rust
// Cache gas costs for common operations
struct GasCostCache {
    sstore_costs: HashMap<(Address, U256, U256), u64>,
    call_costs: HashMap<(Address, Address, U256), u64>,
}

impl GasCostCache {
    fn new() -> Self {
        Self {
            sstore_costs: HashMap::new(),
            call_costs: HashMap::new(),
        }
    }
    
    fn get_sstore_cost(&self, address: Address, key: U256, value: U256) -> Option<u64> {
        self.sstore_costs.get(&(address, key, value)).copied()
    }
    
    fn set_sstore_cost(&mut self, address: Address, key: U256, value: U256, cost: u64) {
        self.sstore_costs.insert((address, key, value), cost);
    }
    
    // Similar methods for call costs
}
```

## Bytecode Execution Optimization

Bytecode execution is often a performance bottleneck, especially for complex contracts.

### Instruction Dispatch Optimization

REVM already optimizes instruction dispatch, but for custom implementations:

```rust
// Fast instruction dispatch using direct indexing
struct FastInstructionTable {
    handlers: [Option<fn(&mut Interpreter<EthInterpreter>) -> Result<(), InterpreterError>>; 256],
}

impl FastInstructionTable {
    fn new() -> Self {
        let mut table = Self {
            handlers: [None; 256],
        };
        
        // Fill the table with opcode implementations
        table.handlers[0x00] = Some(|interp| {
            // STOP implementation
            interp.shared.status = InterpreterStatus::Stop;
            Ok(())
        });
        
        // Add other opcodes...
        
        table
    }
    
    fn execute(&self, interpreter: &mut Interpreter<EthInterpreter>) -> Result<(), InterpreterError> {
        let opcode = interpreter.current_opcode();
        
        if let Some(handler) = self.handlers[opcode as usize] {
            handler(interpreter)
        } else {
            Err(InterpreterError::InvalidOpcode)
        }
    }
}
```

### Just-In-Time Compilation

For extreme performance requirements, consider JIT compilation:

```rust
// This is a simplified example - real JIT compilation is complex
struct JitCompiler {
    cache: HashMap<B256, fn(&mut Interpreter<EthInterpreter>) -> Result<(), InterpreterError>>,
}

impl JitCompiler {
    fn new() -> Self {
        Self {
            cache: HashMap::new(),
        }
    }
    
    fn compile(&mut self, bytecode: &Bytecode) -> Result<fn(&mut Interpreter<EthInterpreter>) -> Result<(), InterpreterError>, JitError> {
        let code_hash = bytecode.hash();
        
        if let Some(handler) = self.cache.get(&code_hash) {
            return Ok(*handler);
        }
        
        // In a real JIT, this would compile the bytecode to native code
        // Here we just return a function that interprets the bytecode
        let handler = |interpreter: &mut Interpreter<EthInterpreter>| {
            // Simplified interpretation
            while !interpreter.shared.status.is_terminated() {
                let opcode = interpreter.current_opcode();
                
                // Execute opcode
                // ...
                
                // Increment PC
                interpreter.increment_pc(1);
            }
            
            Ok(())
        };
        
        self.cache.insert(code_hash, handler);
        
        Ok(handler)
    }
}
```

## Parallel Execution

While Ethereum execution is inherently sequential, some operations can be parallelized.

### Parallel Transaction Validation

```rust
use rayon::prelude::*;

// Validate multiple transactions in parallel
fn validate_transactions(txs: &[TxEnv], state: &impl DatabaseRef) -> Vec<bool> {
    txs.par_iter()
        .map(|tx| validate_transaction(tx, state).is_ok())
        .collect()
}

fn validate_transaction(tx: &TxEnv, state: &impl DatabaseRef) -> Result<(), ValidationError> {
    // Transaction validation logic
    // ...
    
    Ok(())
}
```

### Parallel Precompile Execution

Some precompiles can be executed in parallel:

```rust
// Execute multiple precompiles in parallel
fn execute_precompiles(
    calls: Vec<(Address, Bytes, u64)>,
) -> Vec<Result<PrecompileOutput, PrecompileError>> {
    calls.into_par_iter()
        .map(|(address, input, gas_limit)| {
            match address {
                a if a == address!("0x0000000000000000000000000000000000000001") => ecrecover(&input, gas_limit),
                a if a == address!("0x0000000000000000000000000000000000000002") => sha256(&input, gas_limit),
                // Other precompiles...
                _ => Err(PrecompileError::Unknown),
            }
        })
        .collect()
}
```

## Benchmarking and Profiling

To optimize effectively, you need to measure performance.

### Basic Benchmarking

```rust
use std::time::{Duration, Instant};

// Simple benchmarking function
fn benchmark<F, T>(name: &str, iterations: usize, f: F) -> T
where
    F: Fn() -> T,
{
    let start = Instant::now();
    
    let result = f();
    
    let elapsed = start.elapsed();
    let per_iteration = elapsed / iterations as u32;
    
    println!("Benchmark {}: {} iterations in {:?} ({:?} per iteration)",
        name, iterations, elapsed, per_iteration);
    
    result
}

// Example usage
let result = benchmark("simple_transfer", 1000, || {
    // Execute a simple transfer transaction
    execute_transfer(&mut evm);
});
```

### Comparative Benchmarking

```rust
// Compare different implementations
fn compare_implementations<F, G, T>(
    name: &str,
    iterations: usize,
    baseline: F,
    optimized: G,
) -> (Duration, Duration)
where
    F: Fn() -> T,
    G: Fn() -> T,
{
    println!("Comparing implementations for {}", name);
    
    // Benchmark baseline
    let baseline_start = Instant::now();
    for _ in 0..iterations {
        baseline();
    }
    let baseline_time = baseline_start.elapsed();
    
    // Benchmark optimized
    let optimized_start = Instant::now();
    for _ in 0..iterations {
        optimized();
    }
    let optimized_time = optimized_start.elapsed();
    
    // Print comparison
    println!("  Baseline: {:?} ({:?} per iteration)",
        baseline_time, baseline_time / iterations as u32);
    println!("  Optimized: {:?} ({:?} per iteration)",
        optimized_time, optimized_time / iterations as u32);
    println!("  Speedup: {:.2}x",
        baseline_time.as_secs_f64() / optimized_time.as_secs_f64());
    
    (baseline_time, optimized_time)
}

// Example usage
compare_implementations(
    "state_access",
    1000,
    || {
        // Baseline implementation
        db.basic(address);
    },
    || {
        // Optimized implementation
        cached_db.basic(address);
    },
);
```

### Profiling

For detailed performance analysis, use profiling tools:

```rust
// Collect execution traces for profiling
struct ProfilingInspector {
    traces: Vec<(String, Duration)>,
    start_time: Option<Instant>,
}

impl ProfilingInspector {
    fn new() -> Self {
        Self {
            traces: Vec::new(),
            start_time: None,
        }
    }
}

impl<DB: DatabaseRef> Inspector<DB> for ProfilingInspector {
    fn step(&mut self, interp: &mut Interpreter, _context: &mut EvmContext<'_, DB>) -> InspectorResult {
        let opcode = interp.current_opcode();
        let opcode_name = opcode_name(opcode);
        
        if self.start_time.is_none() {
            self.start_time = Some(Instant::now());
        } else {
            let elapsed = self.start_time.unwrap().elapsed();
            self.traces.push((opcode_name.to_string(), elapsed));
            self.start_time = Some(Instant::now());
        }
        
        InspectorResult::Continue
    }
    
    // Implement other methods...
}

// Use the profiling inspector
let mut inspector = ProfilingInspector::new();
let result = evm.inspect_with_tx(tx, &mut inspector)?;

// Analyze and print profiling data
let mut operation_times: HashMap<String, Duration> = HashMap::new();
for (op, time) in inspector.traces {
    *operation_times.entry(op).or_insert(Duration::from_secs(0)) += time;
}

println!("Profiling results:");
for (op, time) in operation_times.iter() {
    println!("  {}: {:?}", op, time);
}
```

## Performance Tuning for Different Use Cases

Different use cases require different optimization strategies.

### Optimizing for Block Processing

```rust
// Optimizations for processing many transactions in sequence
struct BlockProcessor {
    evm: Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>,
    hot_accounts: HashSet<Address>,
    account_access_count: HashMap<Address, usize>,
}

impl BlockProcessor {
    fn new(db: impl Database) -> Self {
        Self {
            evm: Context::mainnet().with_db(db).build_mainnet(),
            hot_accounts: HashSet::new(),
            account_access_count: HashMap::new(),
        }
    }
    
    fn process_block(&mut self, transactions: &[TxEnv]) -> Result<Vec<ExecutionResult>, Error> {
        let mut results = Vec::with_capacity(transactions.len());
        
        // Pre-warm cache for hot accounts
        for address in &self.hot_accounts {
            self.evm.ctx().db().basic(*address)?;
        }
        
        // Process transactions
        for tx in transactions {
            // Update access statistics
            self.track_access(tx);
            
            // Execute transaction
            self.evm.modify_tx(|t| *t = tx.clone());
            let result = self.evm.transact_commit()?;
            results.push(result);
        }
        
        // Update hot accounts list based on access patterns
        self.update_hot_accounts();
        
        Ok(results)
    }
    
    fn track_access(&mut self, tx: &TxEnv) {
        // Track caller access
        *self.account_access_count.entry(tx.caller).or_insert(0) += 1;
        
        // Track target access
        if let TxKind::Call(target) = tx.kind {
            *self.account_access_count.entry(target).or_insert(0) += 1;
        }
    }
    
    fn update_hot_accounts(&mut self) {
        // Update hot accounts based on access frequency
        self.hot_accounts = self.account_access_count
            .iter()
            .filter(|(_, &count)| count >= 5) // Threshold
            .map(|(&addr, _)| addr)
            .collect();
    }
}
```

### Optimizing for Contract Simulation

```rust
// Optimizations for repeated contract simulations
struct ContractSimulator {
    evm: Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>,
    contract_address: Address,
    baseline_state: HashMap<Address, Account>,
}

impl ContractSimulator {
    fn new(db: impl Database, contract_address: Address) -> Result<Self, Error> {
        let mut evm = Context::mainnet().with_db(db).build_mainnet();
        
        // Store baseline state
        let baseline_state = evm.ctx().journal().state_changes();
        
        Ok(Self {
            evm,
            contract_address,
            baseline_state,
        })
    }
    
    fn simulate_call(&mut self, data: Bytes, caller: Address) -> Result<ExecutionResult, Error> {
        // Reset to baseline state
        self.reset_state();
        
        // Configure the call
        self.evm.modify_tx(|tx| {
            tx.caller = caller;
            tx.kind = TxKind::Call(self.contract_address);
            tx.data = data;
            tx.value = U256::ZERO;
            tx.gas_limit = 1000000;
            tx.gas_price = U256::from(1000000000u64);
        });
        
        // Execute the call
        let result = self.evm.transact()?;
        
        Ok(result.result)
    }
    
    fn reset_state(&mut self) {
        // Reset state to baseline
        // This is more efficient than creating a new EVM instance
        
        // In a real implementation, you would reset the journal
        // and database to the baseline state
    }
}
```

### Optimizing for Multiple EVMs

```rust
// Efficient management of multiple EVM instances
struct EvmPool {
    idle: Vec<Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>>,
    db: Arc<RwLock<CacheDB<EmptyDB>>>,
}

impl EvmPool {
    fn new(size: usize) -> Self {
        let db = Arc::new(RwLock::new(CacheDB::new(EmptyDB::default())));
        
        let mut idle = Vec::with_capacity(size);
        for _ in 0..size {
            let evm_db = CacheDBProxy::new(db.clone());
            let evm = Context::mainnet().with_db(evm_db).build_mainnet();
            idle.push(evm);
        }
        
        Self { idle, db }
    }
    
    fn get(&mut self) -> Option<Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>> {
        self.idle.pop()
    }
    
    fn put(&mut self, evm: Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>) {
        self.idle.push(evm);
    }
}

// Database proxy that shares state between EVM instances
struct CacheDBProxy {
    db: Arc<RwLock<CacheDB<EmptyDB>>>,
}

impl CacheDBProxy {
    fn new(db: Arc<RwLock<CacheDB<EmptyDB>>>) -> Self {
        Self { db }
    }
}

impl Database for CacheDBProxy {
    type Error = DatabaseError;
    
    fn basic(&mut self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        self.db.write().unwrap().basic(address)
    }
    
    // Implement other methods...
}
```

## Real-World Optimization Case Studies

Let's look at some real-world optimization scenarios.

### Case Study 1: Block Builder Optimization

Block builders need to process many transactions quickly to maximize profit:

```rust
// Optimized block builder
struct BlockBuilder {
    evm: Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>,
    pending_txs: Vec<TxEnv>,
    executed_txs: Vec<TxEnv>,
    block_gas_limit: u64,
    cumulative_gas_used: u64,
}

impl BlockBuilder {
    fn new(db: impl Database, block_gas_limit: u64) -> Self {
        Self {
            evm: Context::mainnet().with_db(db).build_mainnet(),
            pending_txs: Vec::new(),
            executed_txs: Vec::new(),
            block_gas_limit,
            cumulative_gas_used: 0,
        }
    }
    
    fn add_transaction(&mut self, tx: TxEnv) {
        // Add to pending queue
        self.pending_txs.push(tx);
    }
    
    fn build_block(&mut self) -> Result<Block, Error> {
        // Sort transactions by gas price (highest first)
        self.pending_txs.sort_by(|a, b| b.gas_price().cmp(&a.gas_price()));
        
        // Process transactions until block is full
        while let Some(tx) = self.pending_txs.pop() {
            // Check if transaction would fit in block
            if self.cumulative_gas_used + tx.gas_limit > self.block_gas_limit {
                // Put back in pending queue
                self.pending_txs.push(tx);
                continue;
            }
            
            // Execute transaction
            self.evm.modify_tx(|t| *t = tx.clone());
            match self.evm.transact_commit() {
                Ok(result) => {
                    // Transaction succeeded
                    self.executed_txs.push(tx);
                    self.cumulative_gas_used += result.gas_used();
                },
                Err(_) => {
                    // Transaction failed, discard it
                }
            }
        }
        
        // Create the block
        let block = Block {
            transactions: self.executed_txs.clone(),
            gas_used: self.cumulative_gas_used,
            // Other block fields...
        };
        
        // Reset for next block
        self.executed_txs.clear();
        self.cumulative_gas_used = 0;
        
        Ok(block)
    }
}
```

### Case Study 2: DApp Simulation Optimization

DApps need to simulate transactions to estimate gas and check validity:

```rust
// Optimized DApp transaction simulator
struct DAppSimulator {
    evm: Evm<MainContext, NoopInspector, EthInstructions<EthInterpreter, MainContext>, EthPrecompiles>,
    contract_address: Address,
    function_gas_estimates: HashMap<[u8; 4], u64>, // Function selector -> gas estimate
}

impl DAppSimulator {
    fn new(db: impl Database, contract_address: Address) -> Self {
        Self {
            evm: Context::mainnet().with_db(db).build_mainnet(),
            contract_address,
            function_gas_estimates: HashMap::new(),
        }
    }
    
    fn simulate_transaction(&mut self, caller: Address, data: Bytes, value: U256) -> Result<SimulationResult, Error> {
        // Extract function selector
        let selector = if data.len() >= 4 {
            let mut sel = [0u8; 4];
            sel.copy_from_slice(&data[0..4]);
            sel
        } else {
            [0u8; 4]
        };
        
        // Get gas estimate from cache or use default
        let gas_estimate = self.function_gas_estimates
            .get(&selector)
            .copied()
            .unwrap_or(1000000);
        
        // Configure transaction
        self.evm.modify_tx(|tx| {
            tx.caller = caller;
            tx.kind = TxKind::Call(self.contract_address);
            tx.data = data.clone();
            tx.value = value;
            tx.gas_limit = gas_estimate;
            tx.gas_price = U256::from(1000000000u64);
        });
        
        // Execute transaction
        match self.evm.transact() {
            Ok(result) => {
                // Update gas estimate based on actual usage
                self.function_gas_estimates.insert(selector, result.result.gas_used());
                
                Ok(SimulationResult {
                    success: result.result.is_success(),
                    gas_used: result.result.gas_used(),
                    return_data: if let Output::Call(data) = &result.result.output {
                        data.clone()
                    } else {
                        Bytes::default()
                    },
                    state_changes: result.state,
                })
            },
            Err(error) => Err(error.into()),
        }
    }
}

struct SimulationResult {
    success: bool,
    gas_used: u64,
    return_data: Bytes,
    state_changes: HashMap<Address, Account>,
}
```

## Summary

Optimizing REVM performance involves several key strategies:

- **Caching**: Implement effective caching for state, code, and analysis
- **Memory Management**: Minimize allocations and optimize memory usage
- **Database Optimization**: Use efficient database implementations and access patterns
- **Gas Calculation**: Optimize gas calculation for common scenarios
- **Bytecode Execution**: Improve instruction dispatch and consider JIT compilation
- **Parallel Execution**: Parallelize independent operations where possible
- **Benchmarking and Profiling**: Measure and identify performance bottlenecks
- **Use Case Specific Optimization**: Tailor optimizations to specific usage patterns

By applying these techniques appropriately, you can significantly improve REVM performance for your specific use case.

## Next Steps

Now that you understand REVM performance considerations, you might want to explore:

- [Integration Patterns](#TODO): Learn how to integrate REVM with other systems
- [EVM Customization](#TODO): Explore how customization can improve performance
- [Expert Reference: Database Components](#TODO): Dive deeper into database optimizations

---

**Note**: The optimization techniques in this document are provided as examples. The effectiveness of each technique depends on your specific use case and environment. Always benchmark and profile before and after optimization to ensure you're achieving the desired performance improvements.